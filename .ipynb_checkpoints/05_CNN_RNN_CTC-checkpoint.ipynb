{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/adityajain07/ctc-lfd/eb8e74c97c2f4e9ebb026150c98d1ca7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author       : Aditya Jain\n",
    "Date Started : This notebook was created on 2nd December, 2020\n",
    "About        : Implementing CNN+RNN+CTC\n",
    "'''\n",
    "# import comet_ml at the top of your file\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Create an experiment with your api key:\n",
    "experiment = Experiment(\n",
    "    api_key=\"epeaAhyRcHSkn92H4kusmbX8k\",\n",
    "    project_name=\"ctc-lfd\",\n",
    "    workspace=\"adityajain07\",\n",
    "    log_code=\"True\"\n",
    ")\n",
    "experiment.set_code()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout, Dense, Input, Reshape, TimeDistributed, Lambda, LSTM, Bidirectional, Conv2D, MaxPooling2D, Flatten\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing MIME Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1773, 30, 800)\n",
      "(1773, 7)\n",
      "{1: 'Reach', 2: 'Tilt', 3: 'Retract', 4: 'Grasp', 5: 'Release'}\n",
      "{'Push': [1, 1, 3], 'Pour': [1, 4, 1, 2, 1, 5, 3], 'Pick': [1, 4, 1, 1, 5, 3], 'Stack': [1, 4, 1, 5, 3]}\n",
      "Training Data:  (1418, 30, 800) (1418, 7)\n",
      "Testing Data:  (355, 30, 800) (355, 7)\n",
      "Total classes of primitives:  6\n",
      "Max label length:  7\n"
     ]
    }
   ],
   "source": [
    "data_read  = pickle.load(open(\"/home/aditya/Dropbox/LearningfromDemons/ctc_data/MIME_full.pickle\",\"rb\"))\n",
    "\n",
    "image_data = data_read['data_image']\n",
    "labels     = data_read['data_label']\n",
    "prim_map   = data_read['primitive_map']\n",
    "label_map  = data_read['label_map']\n",
    "\n",
    "labels  = pad_sequences(labels, padding='post', value = 0)  # making sure all labels are of equal length\n",
    "\n",
    "print(image_data.shape)\n",
    "print(labels.shape)\n",
    "print(prim_map)\n",
    "print(label_map)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.2, random_state=43)  \n",
    "# note: passing a value to random_state produces the exact split every time\n",
    "\n",
    "print(\"Training Data: \", x_train.shape, y_train.shape)\n",
    "print(\"Testing Data: \", x_test.shape, y_test.shape)\n",
    "\n",
    "no_classes    = len(prim_map)+1      # one extra label bcz of padding\n",
    "max_label_len = labels.shape[-1]\n",
    "\n",
    "training_pts  = int(x_train.shape[0])\n",
    "test_pts      = int(x_test.shape[0])\n",
    "\n",
    "print(\"Total classes of primitives: \", no_classes)\n",
    "print(\"Max label length: \", max_label_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training points:  1418\n",
      "Total test points:  355\n"
     ]
    }
   ],
   "source": [
    "print(\"Total training points: \", training_pts)\n",
    "print(\"Total test points: \", test_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 800)\n",
      "<class 'int'>\n",
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 30, 800)]         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 30, 800, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 800, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 400, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 400, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 200, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 200, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 100, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 100, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 50, 64)         0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 128)           66048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50, 7)             903       \n",
      "=================================================================\n",
      "Total params: 159,623\n",
      "Trainable params: 159,623\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#### Doing Here\n",
    "\n",
    "image_shape = x_train.shape[1:]        # the image shape\n",
    "no_channels = 1                        # no of channels in the image, 3 in case of RGB\n",
    "print(image_shape)\n",
    "\n",
    "# no_classes        = 80\n",
    "# max_label_len = 4\n",
    "print(type(image_shape[0]))\n",
    "\n",
    "# architecture is defined below\n",
    "\n",
    "inputs     = Input(shape=image_shape)\n",
    "reshape1   = Reshape((image_shape[0], image_shape[1], 1))(inputs)\n",
    "conv_1     = Conv2D(32, (3,3), activation = 'relu', padding='same')(reshape1)\n",
    "max_pool1  = MaxPooling2D(pool_size=(2, 2))(conv_1)\n",
    "conv_2     = Conv2D(64, (3,3), activation = 'relu', padding='same')(max_pool1)\n",
    "max_pool2  = MaxPooling2D(pool_size=(2, 2))(conv_2)\n",
    "conv_3     = Conv2D(64, (3,3), activation = 'relu', padding='same')(max_pool2)\n",
    "max_pool3  = MaxPooling2D(pool_size=(2, 2))(conv_3)\n",
    "conv_4     = Conv2D(64, (3,3), activation = 'relu', padding='same')(max_pool3)\n",
    "max_pool4  = MaxPooling2D(pool_size=(2, 2))(conv_4)\n",
    "squeezed   = Lambda(lambda x: K.squeeze(x, 1))(max_pool4)\n",
    "# reshape    = Reshape(target_shape=(int(image_shape[0]/8), int(image_shape[1]/8*64)))(max_pool3)\n",
    "# dense1     = Dense(64)(reshape)                                                  # this dense helps reduce no of params\n",
    "blstm1     = Bidirectional(LSTM(64, return_sequences=True))(squeezed)\n",
    "outputs    = Dense(no_classes+1, activation=\"softmax\")(blstm1)\n",
    "\n",
    "\n",
    "model_arch = Model(inputs, outputs)           # for viz the model architecture\n",
    "model_arch.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels       = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    " \n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    " \n",
    "\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
    "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_length = np.asarray([squeezed.shape[1] for i in range(training_pts)])              # the number of timesteps that go as input to LSTM layer\n",
    "train_label_length = np.asarray([max_label_len for i in range(training_pts)])\n",
    "\n",
    "test_input_length = np.asarray([squeezed.shape[1] for i in range(test_pts)])\n",
    "test_label_length = np.asarray([max_label_len for i in range(test_pts)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Callbacks for the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyCallback(keras.callbacks.Callback):\n",
    "    '''\n",
    "    The callback calculates the accuracy on training and test data at the end of every epoch\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, pred_model, x_train, y_train, x_test, y_test):\n",
    "        super(AccuracyCallback, self).__init__()\n",
    "        self.train_acc = 0\n",
    "        self.val_acc  = 0\n",
    "        self.x_train   = x_train\n",
    "        self.y_train   = y_train\n",
    "        self.x_test    = x_test\n",
    "        self.y_test    = y_test\n",
    "        self.weights   = None\n",
    "        self.pred_model= pred_model\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"End of epoch number: \", epoch)\n",
    "#         print(self.x_train.shape, self.y_train.shape)\n",
    "#         print(self.x_test.shape, self.y_test.shape)\n",
    "        \n",
    "        self.model.save_weights('callback_model.hdf5')\n",
    "        self.pred_model.load_weights('callback_model.hdf5')\n",
    "        \n",
    "        self.train_accuracy()\n",
    "        self.val_accuracy()\n",
    "        \n",
    "    def train_accuracy(self):\n",
    "        '''calculates accuracy on train data'''\n",
    "        train_pred = self.pred_model.predict(x_train)\n",
    "        decode_pred = K.get_value(K.ctc_decode(train_pred, input_length=np.ones(train_pred.shape[0])*train_pred.shape[1],\n",
    "                         greedy=True)[0][0])\n",
    "        \n",
    "        train_points = self.x_train.shape[0]\n",
    "        count       = 0\n",
    "        \n",
    "        # removing all extra label or -1's induced by CTC\n",
    "        for i in range(train_points):   \n",
    "            pred_label = []  # the final label\n",
    "            \n",
    "            x = decode_pred[i]\n",
    "            for item in x:\n",
    "                if item!=-1:\n",
    "                    pred_label.append(item)\n",
    "                \n",
    "            pred_label = np.asarray(pred_label)            \n",
    "            if np.array_equal(pred_label,y_train[i]):\n",
    "                count += 1\n",
    "                print(\"Correct Predictions on Train: \", pred_label, y_train[i])\n",
    "        \n",
    "        self.train_acc = count/train_points*100\n",
    "        print(\"The training accuracy is: \", self.train_acc)\n",
    "        \n",
    "    \n",
    "    def val_accuracy(self):\n",
    "        '''calculates accuracy on test data'''\n",
    "        test_pred = self.pred_model.predict(x_test)\n",
    "        decode_pred = K.get_value(K.ctc_decode(test_pred, input_length=np.ones(test_pred.shape[0])*test_pred.shape[1],\n",
    "                         greedy=True)[0][0])\n",
    "        \n",
    "        test_points = self.x_test.shape[0]\n",
    "        count       = 0\n",
    "        \n",
    "        # removing all extra label or -1's induced by CTC\n",
    "        for i in range(test_points):   \n",
    "            pred_label = []  # the final label\n",
    "            \n",
    "            x = decode_pred[i]\n",
    "            for item in x:\n",
    "                if item!=-1:\n",
    "                    pred_label.append(item)\n",
    "                \n",
    "            pred_label = np.asarray(pred_label)            \n",
    "            if np.array_equal(pred_label,y_test[i]):\n",
    "                count += 1\n",
    "                print(\"Correct Predictions on Test: \", pred_label, y_test[i])\n",
    "        \n",
    "        self.val_acc = count/test_points*100\n",
    "        print(\"The validation accuracy is: \", self.val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 3.9803End of epoch number:  0\n",
      "The training accuracy is:  0.0\n",
      "The validation accuracy is:  0.0\n",
      "45/45 [==============================] - 41s 914ms/step - loss: 3.9803 - val_loss: 4.0196\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 3.8752End of epoch number:  1\n",
      "The training accuracy is:  0.0\n",
      "The validation accuracy is:  0.0\n",
      "45/45 [==============================] - 44s 987ms/step - loss: 3.8752 - val_loss: 3.6169\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 3.4243"
     ]
    }
   ],
   "source": [
    "model.fit(x=[x_train, y_train, train_input_length, train_label_length], y=np.zeros(training_pts), epochs=20,\n",
    "         validation_data = ([x_test, y_test, test_input_length, test_label_length], [np.zeros(test_pts)]),\n",
    "         callbacks=[AccuracyCallback(model_arch, x_train, y_train, x_test, y_test)],\n",
    "         batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Calculation\n",
    "After the final epoch is trained, it calculates the training and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     accuracy = model_accuracy(model, input_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the model\n",
    "\n",
    "model.save_weights('first_run.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aditya/miniconda3/envs/ctc_model/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    }
   ],
   "source": [
    "# model.save_weights('first_run.hdf5')\n",
    "model_arch.load_weights('first_run.hdf5')\n",
    " \n",
    "# predict outputs on validation images\n",
    "test_points = 5\n",
    "\n",
    "# Inference data\n",
    "infer_data    = x_train[:test_points]\n",
    "infer_label   = y_train[:test_points]\n",
    "\n",
    "prediction  = model_arch.predict(infer_data)\n",
    "\n",
    "# use CTC decoder\n",
    "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
    "                         greedy=True)[0][0])\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label:  [1 1 3 0 0 0 0]\n",
      "Predicted label:  [1 1 3 0 0]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "True label:  [1 4 1 1 5 3 0]\n",
      "Predicted label:  [1 5]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "True label:  [1 4 1 2 1 5 3]\n",
      "Predicted label:  [1 4 1 5 3 0]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "True label:  [1 4 1 5 3 0 0]\n",
      "Predicted label:  [1 4 1 3 0]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "True label:  [1 4 1 1 5 3 0]\n",
      "Predicted label:  [1 4 1 5 3 0 0]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(test_points):\n",
    "    print(\"True label: \", infer_label[i])\n",
    "    \n",
    "    pred_lab = []\n",
    "    x = out[i]\n",
    "    for i in x:\n",
    "        if i!=-1:\n",
    "            pred_lab.append(i)\n",
    "            \n",
    "    print(\"Predicted label: \", np.asarray(pred_lab))\n",
    "    print(type(infer_label[i]))\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 4])\n",
    "b = np.array([1, 2, 4])\n",
    "\n",
    "np.array_equal(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(a.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
