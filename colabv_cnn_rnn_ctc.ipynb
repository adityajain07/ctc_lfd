{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "colabv_cnn_rnn_ctc.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibxDn0gaUmF2",
        "outputId": "06787548-67f7-401b-d4ac-08c9b4c2dd2b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KZm657xUT1-",
        "outputId": "33fcd0f7-8f4a-468b-9e82-14531407518b"
      },
      "source": [
        "'''\n",
        "Author       : Aditya Jain\n",
        "Date Started : This notebook was created on 2nd December, 2020\n",
        "About        : Implementing CNN+RNN+CTC\n",
        "'''\n",
        "!pip install comet-ml\n",
        "# import comet_ml at the top of your file\n",
        "from comet_ml import Experiment\n",
        "\n",
        "# Create an experiment with your api key:\n",
        "experiment = Experiment(\n",
        "    api_key=\"epeaAhyRcHSkn92H4kusmbX8k\",\n",
        "    project_name=\"ctc-lfd\",\n",
        "    workspace=\"adityajain07\",\n",
        "    log_code=\"True\"\n",
        ")\n",
        "experiment.set_code()\n",
        "experiment.add_tag('Test')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet-ml in /usr/local/lib/python3.6/dist-packages (3.2.8)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet-ml) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (1.12.1)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (7.352.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (2.23.0)\n",
            "Requirement already satisfied: dulwich>=0.20.6; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet-ml) (0.20.14)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet-ml) (1.0.3)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (0.57.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (2.6.0)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (0.10.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml) (2.10)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet-ml) (5.0.6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/adityajain07/ctc-lfd/99729c3a74324588b383aea44a89e47b\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxluWsGCUT2G"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dropout, Dense, Input, Reshape, TimeDistributed, Lambda, LSTM, Bidirectional, Conv2D, MaxPooling2D, Flatten\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import datetime\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# import inference\n",
        "import cv2\n",
        "\n",
        "HOST_DIR = \"/content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP3KjUEFVgrK"
      },
      "source": [
        "import sys\n",
        "sys.path.append(HOST_DIR)\n",
        "import inference"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPtxhoPGUT2H"
      },
      "source": [
        "#### Importing MIME Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqV4Q0qeUT2I",
        "outputId": "55bf33c2-a15f-4129-d02d-e3ffedd577da"
      },
      "source": [
        "WRITE_DIR   = HOST_DIR + \"saved_model/\"\n",
        "DTSTR       = datetime.datetime.now()\n",
        "DTSTR       = DTSTR.strftime(\"%Y-%m-%d-%H-%M\")\n",
        "\n",
        "# data_read  = pickle.load(open(\"/home/aditya/Dropbox/LearningfromDemons/ctc_data/MIME_full.pickle\",\"rb\"))\n",
        "data_read  = pickle.load(open(HOST_DIR + \"MIME_full.pickle\", \"rb\"))\n",
        "\n",
        "image_data = data_read['data_image']\n",
        "labels     = data_read['data_label']\n",
        "prim_map   = data_read['primitive_map']\n",
        "label_map  = data_read['label_map']\n",
        "\n",
        "labels  = pad_sequences(labels, padding='post', value = 0)  # making sure all labels are of equal length\n",
        "\n",
        "print(image_data.shape)\n",
        "print(labels.shape)\n",
        "print(prim_map)\n",
        "print(label_map)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.2, random_state=43)  \n",
        "# note: passing a value to random_state produces the exact split every time\n",
        "\n",
        "print(\"Training Data: \", x_train.shape, y_train.shape)\n",
        "print(\"Testing Data: \", x_test.shape, y_test.shape)\n",
        "\n",
        "no_classes    = len(prim_map)+1      # one extra label bcz of padding\n",
        "max_label_len = labels.shape[-1]\n",
        "\n",
        "training_pts  = int(x_train.shape[0])\n",
        "test_pts      = int(x_test.shape[0])\n",
        "\n",
        "print(\"Total classes of primitives: \", no_classes)\n",
        "print(\"Max label length: \", max_label_len)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1773, 30, 800)\n",
            "(1773, 7)\n",
            "{1: 'Reach', 2: 'Tilt', 3: 'Retract', 4: 'Grasp', 5: 'Release'}\n",
            "{'Push': [1, 1, 3], 'Pour': [1, 4, 1, 2, 1, 5, 3], 'Pick': [1, 4, 1, 1, 5, 3], 'Stack': [1, 4, 1, 5, 3]}\n",
            "Training Data:  (1418, 30, 800) (1418, 7)\n",
            "Testing Data:  (355, 30, 800) (355, 7)\n",
            "Total classes of primitives:  6\n",
            "Max label length:  7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXJNphPyUT2I",
        "outputId": "38461686-d4d9-42c5-f4b8-007c46972b12"
      },
      "source": [
        "print(\"Total training points: \", training_pts)\n",
        "print(\"Total test points: \", test_pts)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training points:  1418\n",
            "Total test points:  355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugYk6ljzUT2J"
      },
      "source": [
        "#### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDbLCiQHUT2J",
        "outputId": "4e99e922-718e-4981-b35a-acde8cc86432"
      },
      "source": [
        "#### Doing Here\n",
        "\n",
        "image_shape = x_train.shape[1:]        # the image shape\n",
        "no_channels = 1                        # no of channels in the image, 3 in case of RGB\n",
        "print(image_shape)\n",
        "\n",
        "# no_classes        = 80\n",
        "# max_label_len = 4\n",
        "print(type(image_shape[0]))\n",
        "\n",
        "# architecture is defined below\n",
        "\n",
        "inputs     = Input(shape=image_shape)\n",
        "reshape1   = Reshape((image_shape[0], image_shape[1], 1))(inputs)\n",
        "conv_1     = Conv2D(32, (3,3), activation = 'relu', padding='same')(reshape1)\n",
        "max_pool1  = MaxPooling2D(pool_size=(2, 2))(conv_1)\n",
        "conv_2     = Conv2D(64, (3,3), activation = 'relu', padding='same')(max_pool1)\n",
        "max_pool2  = MaxPooling2D(pool_size=(2, 2))(conv_2)\n",
        "conv_3     = Conv2D(64, (3,3), activation = 'relu', padding='same')(max_pool2)\n",
        "max_pool3  = MaxPooling2D(pool_size=(2, 2))(conv_3)\n",
        "conv_4     = Conv2D(64, (3,3), activation = 'relu', padding='same')(max_pool3)\n",
        "max_pool4  = MaxPooling2D(pool_size=(2, 2))(conv_4)\n",
        "squeezed   = Lambda(lambda x: K.squeeze(x, 1))(max_pool4)\n",
        "# reshape    = Reshape(target_shape=(int(image_shape[0]/8), int(image_shape[1]/8*64)))(max_pool3)\n",
        "# dense1     = Dense(64)(reshape)                                                  # this dense helps reduce no of params\n",
        "blstm1     = Bidirectional(LSTM(64, return_sequences=True))(squeezed)\n",
        "blstm2     = Bidirectional(LSTM(128, return_sequences=True))(blstm1)\n",
        "outputs    = Dense(no_classes+1, activation=\"softmax\")(blstm2)\n",
        "\n",
        "\n",
        "model_arch = Model(inputs, outputs)           # for viz the model architecture\n",
        "model_arch.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 800)\n",
            "<class 'int'>\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 30, 800)]         0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 30, 800, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 30, 800, 32)       320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 15, 400, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 15, 400, 64)       18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 7, 200, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 200, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 3, 100, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 3, 100, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 1, 50, 64)         0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 50, 64)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 50, 128)           66048     \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 50, 256)           263168    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50, 7)             1799      \n",
            "=================================================================\n",
            "Total params: 423,687\n",
            "Trainable params: 423,687\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShSw8bfBUT2K"
      },
      "source": [
        "#### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9MV9DphUT2K"
      },
      "source": [
        "labels       = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        " \n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        " \n",
        "\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
        "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
        "\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MDOj5hQUT2L"
      },
      "source": [
        "train_input_length = np.asarray([squeezed.shape[1] for i in range(training_pts)])              # the number of timesteps that go as input to LSTM layer\n",
        "train_label_length = np.asarray([max_label_len for i in range(training_pts)])\n",
        "\n",
        "test_input_length = np.asarray([squeezed.shape[1] for i in range(test_pts)])\n",
        "test_label_length = np.asarray([max_label_len for i in range(test_pts)])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n2Wd4lNUT2L"
      },
      "source": [
        "#### Defining Callbacks for the training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsyqMG5tUT2L"
      },
      "source": [
        "class AccuracyCallback(keras.callbacks.Callback):\n",
        "    '''\n",
        "    The callback calculates the accuracy on training and test data at the end of every epoch\n",
        "    \n",
        "    Arguments:\n",
        "    \n",
        "    '''\n",
        "    def __init__(self, pred_model, x_train, y_train, x_test, y_test, experiment):\n",
        "        super(AccuracyCallback, self).__init__()\n",
        "        self.train_acc = 0\n",
        "        self.val_acc  = 0\n",
        "        self.x_train   = x_train\n",
        "        self.y_train   = y_train\n",
        "        self.x_test    = x_test\n",
        "        self.y_test    = y_test\n",
        "        self.weights   = None\n",
        "        self.pred_model= pred_model\n",
        "        self.train_ser = 100 - self.train_acc     # sequence error rate for training data\n",
        "        self.val_ser   = 100 - self.val_acc       # sequence error rate for validation data\n",
        "        # self.experiment = experiment\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(\"End of epoch number: \", epoch)\n",
        "        \n",
        "        self.model.save_weights('callback_model.hdf5')\n",
        "        self.pred_model.load_weights('callback_model.hdf5')\n",
        "        \n",
        "        self.train_accuracy()\n",
        "        self.val_accuracy()\n",
        "\n",
        "        experiment.log_metric(\"Train - Sequence Error Rate (SER)\", self.train_ser)\n",
        "        experiment.log_metric(\"Validatoin - Label Error Rate (LER)\", self.val_ser)\n",
        "\n",
        "        \n",
        "    def train_accuracy(self):\n",
        "        '''calculates accuracy on train data'''\n",
        "        train_pred = self.pred_model.predict(x_train)\n",
        "        decode_pred = K.get_value(K.ctc_decode(train_pred, input_length=np.ones(train_pred.shape[0])*train_pred.shape[1],\n",
        "                         greedy=True)[0][0])\n",
        "        \n",
        "        train_points = self.x_train.shape[0]\n",
        "        count       = 0\n",
        "        \n",
        "        # removing all extra label or -1's induced by CTC\n",
        "        for i in range(train_points):   \n",
        "            pred_label = []  # the final label\n",
        "            \n",
        "            x = decode_pred[i]\n",
        "            for item in x:\n",
        "                if item!=-1:\n",
        "                    pred_label.append(item)\n",
        "                \n",
        "            pred_label = np.asarray(pred_label)            \n",
        "            if np.array_equal(pred_label,y_train[i]):\n",
        "                count += 1\n",
        "#                 print(\"Correct Predictions on Train: \", pred_label, y_train[i])\n",
        "        \n",
        "        self.train_acc = count/train_points*100\n",
        "        print(\"The training accuracy is: \", self.train_acc)\n",
        "        \n",
        "    \n",
        "    def val_accuracy(self):\n",
        "        '''calculates accuracy on test data'''\n",
        "        test_pred = self.pred_model.predict(x_test)\n",
        "        decode_pred = K.get_value(K.ctc_decode(test_pred, input_length=np.ones(test_pred.shape[0])*test_pred.shape[1],\n",
        "                         greedy=True)[0][0])\n",
        "        \n",
        "        test_points = self.x_test.shape[0]\n",
        "        count       = 0\n",
        "        \n",
        "        # removing all extra label or -1's induced by CTC\n",
        "        for i in range(test_points):   \n",
        "            pred_label = []  # the final label\n",
        "            \n",
        "            x = decode_pred[i]\n",
        "            for item in x:\n",
        "                if item!=-1:\n",
        "                    pred_label.append(item)\n",
        "                \n",
        "            pred_label = np.asarray(pred_label)            \n",
        "            if np.array_equal(pred_label,y_test[i]):\n",
        "                count += 1\n",
        "#                 print(\"Correct Predictions on Test: \", pred_label, y_test[i])\n",
        "        \n",
        "        self.val_acc = count/test_points*100\n",
        "        print(\"The validation accuracy is: \", self.val_acc)\n",
        "        \n",
        "        \n",
        "model_save_callback = ModelCheckpoint(WRITE_DIR + \"best_model-\" + DTSTR + \".hdf5\", monitor='val_loss', verbose=1,\n",
        "    save_best_only=True, mode='auto')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RrUExzgUT2Q"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dCGvY1QxUT2T",
        "outputId": "b80f83c9-b186-450c-f3e4-3610fcb0a3e7"
      },
      "source": [
        "EPOCHS      = 200\n",
        "\n",
        "model.fit(x=[x_train, y_train, train_input_length, train_label_length], y=np.zeros(training_pts), epochs=EPOCHS,\n",
        "         validation_data = ([x_test, y_test, test_input_length, test_label_length], [np.zeros(test_pts)]),\n",
        "         callbacks=[AccuracyCallback(model_arch, x_train, y_train, x_test, y_test, experiment), model_save_callback],\n",
        "         batch_size=32, verbose=0)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "End of epoch number:  0\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 7.92617, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  1\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00002: val_loss improved from 7.92617 to 5.96548, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  2\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00003: val_loss improved from 5.96548 to 5.65342, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  3\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00004: val_loss improved from 5.65342 to 4.91306, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  4\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00005: val_loss improved from 4.91306 to 3.96274, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  5\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.96274 to 3.59885, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  6\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 3.59885\n",
            "End of epoch number:  7\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00008: val_loss improved from 3.59885 to 3.42159, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  8\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 3.42159\n",
            "End of epoch number:  9\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00010: val_loss improved from 3.42159 to 3.36699, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  10\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00011: val_loss improved from 3.36699 to 3.21940, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  11\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00012: val_loss improved from 3.21940 to 2.89135, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  12\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00013: val_loss improved from 2.89135 to 2.63385, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  13\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00014: val_loss improved from 2.63385 to 2.58044, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  14\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 2.58044\n",
            "End of epoch number:  15\n",
            "The training accuracy is:  0.0\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00016: val_loss improved from 2.58044 to 2.53392, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  16\n",
            "The training accuracy is:  0.07052186177715092\n",
            "The validation accuracy is:  0.0\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 2.53392\n",
            "End of epoch number:  17\n",
            "The training accuracy is:  7.968970380818054\n",
            "The validation accuracy is:  7.887323943661972\n",
            "\n",
            "Epoch 00018: val_loss improved from 2.53392 to 2.19183, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  18\n",
            "The training accuracy is:  7.6163610719323\n",
            "The validation accuracy is:  8.169014084507042\n",
            "\n",
            "Epoch 00019: val_loss improved from 2.19183 to 2.07469, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  19\n",
            "The training accuracy is:  12.764456981664315\n",
            "The validation accuracy is:  12.676056338028168\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 2.07469\n",
            "End of epoch number:  20\n",
            "The training accuracy is:  14.174894217207335\n",
            "The validation accuracy is:  12.394366197183098\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 2.07469\n",
            "End of epoch number:  21\n",
            "The training accuracy is:  15.867418899858956\n",
            "The validation accuracy is:  14.647887323943662\n",
            "\n",
            "Epoch 00022: val_loss improved from 2.07469 to 1.89583, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  22\n",
            "The training accuracy is:  24.259520451339917\n",
            "The validation accuracy is:  25.915492957746476\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.89583 to 1.63569, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  23\n",
            "The training accuracy is:  30.818053596614952\n",
            "The validation accuracy is:  28.169014084507044\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.63569\n",
            "End of epoch number:  24\n",
            "The training accuracy is:  37.9407616361072\n",
            "The validation accuracy is:  41.971830985915496\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.63569 to 1.45790, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  25\n",
            "The training accuracy is:  33.568406205923836\n",
            "The validation accuracy is:  35.49295774647888\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.45790\n",
            "End of epoch number:  26\n",
            "The training accuracy is:  38.15232722143865\n",
            "The validation accuracy is:  38.309859154929576\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.45790 to 1.34511, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  27\n",
            "The training accuracy is:  38.645980253878705\n",
            "The validation accuracy is:  40.28169014084507\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.34511 to 1.22222, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  28\n",
            "The training accuracy is:  42.877291960507755\n",
            "The validation accuracy is:  44.50704225352113\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.22222 to 1.10687, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  29\n",
            "The training accuracy is:  43.22990126939351\n",
            "The validation accuracy is:  43.94366197183099\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.10687 to 1.06482, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  30\n",
            "The training accuracy is:  45.839210155148095\n",
            "The validation accuracy is:  46.19718309859155\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.06482\n",
            "End of epoch number:  31\n",
            "The training accuracy is:  39.21015514809591\n",
            "The validation accuracy is:  39.718309859154935\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.06482\n",
            "End of epoch number:  32\n",
            "The training accuracy is:  46.33286318758815\n",
            "The validation accuracy is:  49.29577464788733\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.06482 to 1.06007, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  33\n",
            "The training accuracy is:  51.198871650211565\n",
            "The validation accuracy is:  52.95774647887323\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.06007 to 0.83297, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  34\n",
            "The training accuracy is:  40.267983074753175\n",
            "The validation accuracy is:  40.845070422535215\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.83297\n",
            "End of epoch number:  35\n",
            "The training accuracy is:  74.89421720733426\n",
            "The validation accuracy is:  75.77464788732394\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.83297 to 0.72740, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  36\n",
            "The training accuracy is:  87.37658674188998\n",
            "The validation accuracy is:  84.78873239436619\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.72740 to 0.62618, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  37\n",
            "The training accuracy is:  91.3963328631876\n",
            "The validation accuracy is:  89.01408450704226\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.62618 to 0.51325, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  38\n",
            "The training accuracy is:  85.89562764456981\n",
            "The validation accuracy is:  81.97183098591549\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.51325\n",
            "End of epoch number:  39\n",
            "The training accuracy is:  78.98448519040903\n",
            "The validation accuracy is:  76.61971830985915\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.51325\n",
            "End of epoch number:  40\n",
            "The training accuracy is:  66.57263751763047\n",
            "The validation accuracy is:  63.38028169014085\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.51325\n",
            "End of epoch number:  41\n",
            "The training accuracy is:  96.12129760225669\n",
            "The validation accuracy is:  92.11267605633803\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.51325 to 0.31778, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  42\n",
            "The training accuracy is:  93.93511988716502\n",
            "The validation accuracy is:  92.3943661971831\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.31778\n",
            "End of epoch number:  43\n",
            "The training accuracy is:  95.90973201692525\n",
            "The validation accuracy is:  92.67605633802816\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.31778 to 0.31302, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  44\n",
            "The training accuracy is:  95.20451339915374\n",
            "The validation accuracy is:  92.3943661971831\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.31302\n",
            "End of epoch number:  45\n",
            "The training accuracy is:  95.20451339915374\n",
            "The validation accuracy is:  91.54929577464789\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.31302 to 0.28588, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  46\n",
            "The training accuracy is:  97.60225669957687\n",
            "The validation accuracy is:  93.2394366197183\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.28588 to 0.26223, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  47\n",
            "The training accuracy is:  93.01833568406207\n",
            "The validation accuracy is:  90.14084507042254\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.26223\n",
            "End of epoch number:  48\n",
            "The training accuracy is:  82.93370944992948\n",
            "The validation accuracy is:  81.69014084507043\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.26223\n",
            "End of epoch number:  49\n",
            "The training accuracy is:  96.4033850493653\n",
            "The validation accuracy is:  90.98591549295774\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.26223\n",
            "End of epoch number:  50\n",
            "The training accuracy is:  96.75599435825106\n",
            "The validation accuracy is:  93.52112676056338\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.26223\n",
            "End of epoch number:  51\n",
            "The training accuracy is:  96.96755994358251\n",
            "The validation accuracy is:  93.80281690140845\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.26223 to 0.24991, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  52\n",
            "The training accuracy is:  96.75599435825106\n",
            "The validation accuracy is:  92.67605633802816\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.24991\n",
            "End of epoch number:  53\n",
            "The training accuracy is:  99.36530324400564\n",
            "The validation accuracy is:  95.77464788732394\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.24991 to 0.19460, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  54\n",
            "The training accuracy is:  98.80112834978844\n",
            "The validation accuracy is:  95.77464788732394\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.19460\n",
            "End of epoch number:  55\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.19460 to 0.14425, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  56\n",
            "The training accuracy is:  99.4358251057828\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.14425\n",
            "End of epoch number:  57\n",
            "The training accuracy is:  99.8589562764457\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.14425\n",
            "End of epoch number:  58\n",
            "The training accuracy is:  99.64739069111424\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.14425 to 0.13499, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  59\n",
            "The training accuracy is:  99.29478138222849\n",
            "The validation accuracy is:  96.90140845070422\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.13499\n",
            "End of epoch number:  60\n",
            "The training accuracy is:  94.99294781382228\n",
            "The validation accuracy is:  91.83098591549296\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.13499\n",
            "End of epoch number:  61\n",
            "The training accuracy is:  99.08321579689704\n",
            "The validation accuracy is:  93.80281690140845\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.13499\n",
            "End of epoch number:  62\n",
            "The training accuracy is:  99.5768688293371\n",
            "The validation accuracy is:  95.77464788732394\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.13499\n",
            "End of epoch number:  63\n",
            "The training accuracy is:  98.94217207334273\n",
            "The validation accuracy is:  94.64788732394366\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.13499\n",
            "End of epoch number:  64\n",
            "The training accuracy is:  99.71791255289139\n",
            "The validation accuracy is:  95.49295774647887\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.13499\n",
            "End of epoch number:  65\n",
            "The training accuracy is:  99.71791255289139\n",
            "The validation accuracy is:  96.05633802816902\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.13499 to 0.13406, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  66\n",
            "The training accuracy is:  99.8589562764457\n",
            "The validation accuracy is:  95.2112676056338\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.13406\n",
            "End of epoch number:  67\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  95.49295774647887\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.13406\n",
            "End of epoch number:  68\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.13406 to 0.11327, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  69\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.74647887323944\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.11327 to 0.11083, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  70\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  96.90140845070422\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.11083\n",
            "End of epoch number:  71\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.11083 to 0.10726, saving model to /content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/saved_model/best_model-2020-12-18-10-35.hdf5\n",
            "End of epoch number:  72\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  96.90140845070422\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.10726\n",
            "End of epoch number:  73\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  96.90140845070422\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.10726\n",
            "End of epoch number:  74\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.10726\n",
            "End of epoch number:  75\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.74647887323944\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.10726\n",
            "End of epoch number:  76\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.10726\n",
            "End of epoch number:  77\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.10726\n",
            "End of epoch number:  78\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.10726\n",
            "End of epoch number:  79\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.10726\n",
            "End of epoch number:  80\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.10726\n",
            "End of epoch number:  81\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.10726\n",
            "End of epoch number:  82\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.10726\n",
            "End of epoch number:  83\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.10726\n",
            "End of epoch number:  84\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.74647887323944\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.10726\n",
            "End of epoch number:  85\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.10726\n",
            "End of epoch number:  86\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.10726\n",
            "End of epoch number:  87\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.10726\n",
            "End of epoch number:  88\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.10726\n",
            "End of epoch number:  89\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.10726\n",
            "End of epoch number:  90\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.10726\n",
            "End of epoch number:  91\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.10726\n",
            "End of epoch number:  92\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.10726\n",
            "End of epoch number:  93\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.10726\n",
            "End of epoch number:  94\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.10726\n",
            "End of epoch number:  95\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.10726\n",
            "End of epoch number:  96\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.10726\n",
            "End of epoch number:  97\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.10726\n",
            "End of epoch number:  98\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.10726\n",
            "End of epoch number:  99\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.10726\n",
            "End of epoch number:  100\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.10726\n",
            "End of epoch number:  101\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.10726\n",
            "End of epoch number:  102\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.10726\n",
            "End of epoch number:  103\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  96.90140845070422\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.10726\n",
            "End of epoch number:  104\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.10726\n",
            "End of epoch number:  105\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.10726\n",
            "End of epoch number:  106\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.10726\n",
            "End of epoch number:  107\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.10726\n",
            "End of epoch number:  108\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.10726\n",
            "End of epoch number:  109\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.10726\n",
            "End of epoch number:  110\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.10726\n",
            "End of epoch number:  111\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.10726\n",
            "End of epoch number:  112\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.10726\n",
            "End of epoch number:  113\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.10726\n",
            "End of epoch number:  114\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.10726\n",
            "End of epoch number:  115\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.10726\n",
            "End of epoch number:  116\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.10726\n",
            "End of epoch number:  117\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.10726\n",
            "End of epoch number:  118\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.10726\n",
            "End of epoch number:  119\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.10726\n",
            "End of epoch number:  120\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.10726\n",
            "End of epoch number:  121\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.1830985915493\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.10726\n",
            "End of epoch number:  122\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.10726\n",
            "End of epoch number:  123\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.10726\n",
            "End of epoch number:  124\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.10726\n",
            "End of epoch number:  125\n",
            "The training accuracy is:  100.0\n",
            "The validation accuracy is:  97.46478873239437\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.10726\n",
            "End of epoch number:  126\n",
            "The training accuracy is:  100.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3287c851d69a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m          \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAccuracyCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_arch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m          batch_size=32, verbose=0)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/comet_ml/monkey_patching.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m                     )\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Call after callbacks once we have the return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/comet_ml/monkey_patching.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m                     )\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Call after callbacks once we have the return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-579a24136e76>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-579a24136e76>\u001b[0m in \u001b[0;36mval_accuracy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;34m'''calculates accuracy on test data'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         decode_pred = K.get_value(K.ctc_decode(test_pred, input_length=np.ones(test_pred.shape[0])*test_pred.shape[1],\n\u001b[1;32m     64\u001b[0m                          greedy=True)[0][0])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFqE48Ejd8XC",
        "outputId": "cd3b39c2-a41b-4132-fa60-54837c5addb6"
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.ml/adityajain07/ctc-lfd/99729c3a74324588b383aea44a89e47b\n",
            "COMET INFO:   Metrics [count] (min, max):\n",
            "COMET INFO:     batch_loss [635]          : (0.00038773202686570585, 68.7678451538086)\n",
            "COMET INFO:     epoch_duration [126]      : (3.076627430999906, 11.367121629999929)\n",
            "COMET INFO:     loss [126]                : (0.0004663619038183242, 15.626677513122559)\n",
            "COMET INFO:     train_accuracy [126]      : (0.0, 100.0)\n",
            "COMET INFO:     val_loss [126]            : (0.10726311802864075, 7.9261698722839355)\n",
            "COMET INFO:     validate_batch_loss [254] : (0.014568752609193325, 7.921794414520264)\n",
            "COMET INFO:     validation_accuracy [126] : (0.0, 97.74647887323944)\n",
            "COMET INFO:   Others:\n",
            "COMET INFO:     trainable_params : 423687\n",
            "COMET INFO:   Parameters:\n",
            "COMET INFO:     Adam_amsgrad       : 1\n",
            "COMET INFO:     Adam_beta_1        : 0.9\n",
            "COMET INFO:     Adam_beta_2        : 0.999\n",
            "COMET INFO:     Adam_decay         : 1\n",
            "COMET INFO:     Adam_epsilon       : 1e-07\n",
            "COMET INFO:     Adam_learning_rate : 0.001\n",
            "COMET INFO:     Adam_name          : Adam\n",
            "COMET INFO:     Optimizer          : Adam\n",
            "COMET INFO:     epochs             : 200\n",
            "COMET INFO:     steps              : 45\n",
            "COMET INFO:   Uploads:\n",
            "COMET INFO:     code                : 1 (26 KB)\n",
            "COMET INFO:     environment details : 1\n",
            "COMET INFO:     filename            : 1\n",
            "COMET INFO:     installed packages  : 1\n",
            "COMET INFO:     model graph         : 1\n",
            "COMET INFO:     notebook            : 1\n",
            "COMET INFO:     os packages         : 1\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Still uploading\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb80sWEcUT2T"
      },
      "source": [
        "#### Save and Load Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMX1EcWnUT2U"
      },
      "source": [
        "model.save_weights('first_run.hdf5')\n",
        "model_arch.load_weights('first_run.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9jheC_KUT2U"
      },
      "source": [
        "#### Inference on a single test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doBY4PybUT2U",
        "outputId": "974568ae-a329-4d1a-b255-f5a318caf6ae"
      },
      "source": [
        "video_path     = \"/content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC-MIME/stacking1.avi\"\n",
        "\n",
        "# These params cannot be changed\n",
        "desired_shape  = (30, 800)\n",
        "n_frames       = 10\n",
        "down_f         = 8\n",
        "\n",
        "infer_object   = inference.Inference(video_path, n_frames, down_f, desired_shape, model_arch)\n",
        "image = infer_object.prep_data()\n",
        "predicted_out, final_out = infer_object.predict()\n",
        "\n",
        "print(\"Raw output: \", predicted_out)\n",
        "print(\"Final processed output: \", final_out)\n",
        "print('\\n')\n",
        "\n",
        "for primtive in final_out:\n",
        "    if primtive==0:\n",
        "        continue\n",
        "    else:\n",
        "        print(prim_map[primtive])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw output:  [ 1  4  1  1  5  3  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1]\n",
            "Final processed output:  [1 4 1 1 5 3 0]\n",
            "\n",
            "\n",
            "Reach\n",
            "Grasp\n",
            "Reach\n",
            "Reach\n",
            "Release\n",
            "Retract\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHEMFlbbUT2U"
      },
      "source": [
        "### Miscellaneous (Do Not Run)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-98UU8eUT2V",
        "outputId": "368fe16c-c700-4fc2-a5bc-12f10353641c"
      },
      "source": [
        "## Saving the model\n",
        "\n",
        "model.save_weights('first_run.hdf5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f3860cb5fe1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Saving the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'first_run.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eCpPxE7UT2V",
        "outputId": "fb9d4001-83b8-434e-c814-6786ce933b7d"
      },
      "source": [
        "# model.save_weights('first_run.hdf5')\n",
        "# model_arch.load_weights('first_run.hdf5')\n",
        " \n",
        "# predict outputs on validation images\n",
        "test_points = 2\n",
        "\n",
        "# Inference data\n",
        "infer_data    = x_train[:test_points]\n",
        "infer_label   = y_train[:test_points]\n",
        "\n",
        "prediction  = model_arch.predict(infer_data)\n",
        "\n",
        "# use CTC decoder\n",
        "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
        "                         greedy=True)[0][0])\n",
        " \n",
        "\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  4  1  1  5  3  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            "  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            "  -1 -1]\n",
            " [ 1  4  1  5  3  0  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            "  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            "  -1 -1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mFzuhEQUT2W",
        "outputId": "c0f0acae-9e68-48f2-afb7-c58a6a0554cc"
      },
      "source": [
        "for i in range(test_points):\n",
        "    print(\"True label: \", infer_label[i])\n",
        "    \n",
        "    pred_lab = []\n",
        "    x = out[i]\n",
        "    for i in x:\n",
        "        if i!=-1:\n",
        "            pred_lab.append(i)\n",
        "            \n",
        "    print(\"Predicted label: \", np.asarray(pred_lab))\n",
        "    print(type(infer_label[i]))\n",
        "    print('\\n')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True label:  [1 4 1 1 5 3 0]\n",
            "Predicted label:  [1 4 1 1 5 3 0]\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "\n",
            "True label:  [1 4 1 5 3 0 0]\n",
            "Predicted label:  [1 4 1 5 3 0 0]\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABMqHME9UT2W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}