{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "colabv_cnn_rnn_ctc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibxDn0gaUmF2",
        "outputId": "a796fcc6-a81d-4980-a872-1f2bf34f7a40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KZm657xUT1-",
        "outputId": "dcd18371-ad56-4da9-be4f-355794a68666"
      },
      "source": [
        "'''\n",
        "Author       : Aditya Jain\n",
        "Date Started : This notebook was created on 2nd December, 2020\n",
        "About        : Implementing CNN+RNN+CTC\n",
        "'''\n",
        "!pip install editdistance\n",
        "!pip install comet-ml\n",
        "# import comet_ml at the top of your file\n",
        "from comet_ml import Experiment\n",
        "\n",
        "# Create an experiment with your api key:\n",
        "experiment = Experiment(\n",
        "    api_key=\"epeaAhyRcHSkn92H4kusmbX8k\",\n",
        "    project_name=\"ctc-lfd\",\n",
        "    workspace=\"adityajain07\",\n",
        "    log_code=\"True\"\n",
        ")\n",
        "experiment.set_code()\n",
        "experiment.add_tag('2_Mixing the two datasets')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (0.5.3)\n",
            "Requirement already satisfied: comet-ml in /usr/local/lib/python3.6/dist-packages (3.2.9)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet-ml) (1.0.3)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (1.12.1)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (2.23.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (2.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet-ml) (1.15.0)\n",
            "Requirement already satisfied: dulwich>=0.20.6; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet-ml) (0.20.15)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (0.57.0)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (0.10.9)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (7.352.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet-ml) (2.0.1)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet-ml) (5.0.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml) (3.0.4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/adityajain07/ctc-lfd/187889dffbf04c46ac573ef030c4609f\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxluWsGCUT2G"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dropout, Dense, Input, Reshape, TimeDistributed, Lambda, LSTM, Bidirectional, Conv2D, MaxPooling2D, Flatten\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import datetime\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import editdistance\n",
        "\n",
        "\n",
        "# import inference\n",
        "import cv2\n",
        "\n",
        "HOST_DIR = \"/content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC_Code/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP3KjUEFVgrK"
      },
      "source": [
        "import sys\n",
        "sys.path.append(HOST_DIR)\n",
        "import inference"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPtxhoPGUT2H"
      },
      "source": [
        "#### Importing MIME Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqV4Q0qeUT2I",
        "outputId": "f8f67164-2183-4cbc-c562-8f0a8e6ac5a1"
      },
      "source": [
        "WRITE_DIR   = HOST_DIR + \"saved_model/\"\n",
        "DTSTR       = datetime.datetime.now()\n",
        "DTSTR       = DTSTR.strftime(\"%Y-%m-%d-%H-%M\")\n",
        "\n",
        "# data_read  = pickle.load(open(\"/home/aditya/Dropbox/LearningfromDemons/ctc_data/MIME_full.pickle\",\"rb\"))\n",
        "data_read  = pickle.load(open(HOST_DIR + \"MIME_full.pickle\", \"rb\"))\n",
        "\n",
        "image_data = data_read['data_image']\n",
        "labels     = data_read['data_label']\n",
        "prim_map   = data_read['primitive_map']\n",
        "label_map  = data_read['label_map']\n",
        "\n",
        "labels  = pad_sequences(labels, padding='post', value = 0)  # making sure all labels are of equal length\n",
        "\n",
        "print(image_data.shape)\n",
        "print(labels.shape)\n",
        "print(prim_map)\n",
        "print(label_map)\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.2, random_state=43)  \n",
        "# note: passing a value to random_state produces the exact split every time\n",
        "x_train   = image_data\n",
        "y_train   = labels\n",
        "\n",
        "# Case 1: Train on MIME, Test on Self Data\n",
        "test_data = pickle.load(open(HOST_DIR + \"MIME_self-v1.pickle\", \"rb\"))\n",
        "\n",
        "x_test    = test_data['data_image']\n",
        "y_test    = pad_sequences(test_data['data_label'], padding='post', value = 0)  # making sure all labels are of equal length\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1773, 30, 800)\n",
            "(1773, 7)\n",
            "{1: 'Reach', 2: 'Tilt', 3: 'Retract', 4: 'Grasp', 5: 'Release'}\n",
            "{'Push': [1, 1, 3], 'Pour': [1, 4, 1, 2, 1, 5, 3], 'Pick': [1, 4, 1, 1, 5, 3], 'Stack': [1, 4, 1, 5, 3]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k08hyvXQnBd4"
      },
      "source": [
        "# Case 2: Mixing the two datasets\n",
        "\n",
        "final_data  = np.concatenate([x_train, x_test])\n",
        "final_label = np.concatenate([y_train, y_test])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(final_data, final_label, test_size=0.2, random_state=43)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJMXpIoHidhy",
        "outputId": "a5974af0-4e6d-4648-ee43-10756e639b95"
      },
      "source": [
        "print(\"Training Data: \", x_train.shape, y_train.shape)\n",
        "print(\"Testing Data: \", x_test.shape, y_test.shape)\n",
        "\n",
        "no_classes    = len(prim_map)+1      # one extra label bcz of padding\n",
        "max_label_len = labels.shape[-1]\n",
        "\n",
        "training_pts  = int(x_train.shape[0])\n",
        "test_pts      = int(x_test.shape[0])\n",
        "\n",
        "print(\"Total classes of primitives: \", no_classes)\n",
        "print(\"Max label length: \", max_label_len)\n",
        "\n",
        "print(\"Total training points: \", training_pts)\n",
        "print(\"Total test points: \", test_pts)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:  (1773, 30, 800) (1773, 7)\n",
            "Testing Data:  (160, 30, 800) (160, 7)\n",
            "Total classes of primitives:  6\n",
            "Max label length:  7\n",
            "Total training points:  1773\n",
            "Total test points:  160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugYk6ljzUT2J"
      },
      "source": [
        "#### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDbLCiQHUT2J",
        "outputId": "2e36607b-022a-4dfd-dbf2-08e894124a9d"
      },
      "source": [
        "#### Doing Here\n",
        "\n",
        "image_shape = x_train.shape[1:]        # the image shape\n",
        "no_channels = 1                        # no of channels in the image, 3 in case of RGB\n",
        "print(image_shape)\n",
        "\n",
        "# no_classes        = 80\n",
        "# max_label_len = 4\n",
        "print(type(image_shape[0]))\n",
        "\n",
        "# architecture is defined below\n",
        "\n",
        "inputs     = Input(shape=image_shape)\n",
        "reshape1   = Reshape((image_shape[0], image_shape[1], 1))(inputs)\n",
        "conv_1     = Conv2D(32, (3,3), activation = 'relu', padding='same')(reshape1)\n",
        "max_pool1  = MaxPooling2D(pool_size=(2, 2))(conv_1)\n",
        "conv_2     = Conv2D(64, (3,3), activation = 'relu', padding='same')(max_pool1)\n",
        "max_pool2  = MaxPooling2D(pool_size=(2, 2))(conv_2)\n",
        "conv_3     = Conv2D(64, (3,3), activation = 'relu', padding='same')(max_pool2)\n",
        "max_pool3  = MaxPooling2D(pool_size=(2, 2))(conv_3)\n",
        "conv_4     = Conv2D(64, (3,3), activation = 'relu', padding='same')(max_pool3)\n",
        "max_pool4  = MaxPooling2D(pool_size=(2, 2))(conv_4)\n",
        "squeezed   = Lambda(lambda x: K.squeeze(x, 1))(max_pool4)\n",
        "# reshape    = Reshape(target_shape=(int(image_shape[0]/8), int(image_shape[1]/8*64)))(max_pool3)\n",
        "# dense1     = Dense(64)(reshape)                                                  # this dense helps reduce no of params\n",
        "blstm1     = Bidirectional(LSTM(64, return_sequences=True))(squeezed)\n",
        "blstm2     = Bidirectional(LSTM(128, return_sequences=True))(blstm1)\n",
        "outputs    = Dense(no_classes+1, activation=\"softmax\")(blstm2)\n",
        "\n",
        "\n",
        "model_arch = Model(inputs, outputs)           # for viz the model architecture\n",
        "model_arch.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 800)\n",
            "<class 'int'>\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 30, 800)]         0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 30, 800, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 30, 800, 32)       320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 400, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 15, 400, 64)       18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 200, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 200, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 100, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 100, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 50, 64)         0         \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 50, 64)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 50, 128)           66048     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 50, 256)           263168    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50, 7)             1799      \n",
            "=================================================================\n",
            "Total params: 423,687\n",
            "Trainable params: 423,687\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShSw8bfBUT2K"
      },
      "source": [
        "#### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9MV9DphUT2K"
      },
      "source": [
        "labels       = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        " \n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        " \n",
        "\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
        "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
        "\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MDOj5hQUT2L"
      },
      "source": [
        "train_input_length = np.asarray([squeezed.shape[1] for i in range(training_pts)])              # the number of timesteps that go as input to LSTM layer\n",
        "train_label_length = np.asarray([max_label_len for i in range(training_pts)])\n",
        "\n",
        "test_input_length = np.asarray([squeezed.shape[1] for i in range(test_pts)])\n",
        "test_label_length = np.asarray([max_label_len for i in range(test_pts)])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n2Wd4lNUT2L"
      },
      "source": [
        "#### Defining Callbacks for the training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsyqMG5tUT2L"
      },
      "source": [
        "class MetricCallback(keras.callbacks.Callback):\n",
        "    '''\n",
        "    This callback calculates various metrics on training and validation data at the end of every epoch\n",
        "    \n",
        "    Arguments:\n",
        "    \n",
        "    '''\n",
        "    def __init__(self, pred_model, x_train, y_train, x_test, y_test, experiment):\n",
        "        super(MetricCallback, self).__init__()\n",
        "        self.train_acc = 0\n",
        "        self.val_acc  = 0\n",
        "        self.x_train   = x_train\n",
        "        self.y_train   = y_train\n",
        "        self.x_test    = x_test\n",
        "        self.y_test    = y_test\n",
        "        self.weights   = None\n",
        "        self.pred_model= pred_model\n",
        "\n",
        "        # final metrics of interest\n",
        "        self.train_ser = 0     # sequence error rate for training data\n",
        "        self.val_ser   = 0     # sequence error rate for validation data\n",
        "        self.train_ler = 0     # label error rate on training data\n",
        "        self.val_ler   = 0     # label error rate on validation data\n",
        "\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(\"End of epoch number: \", epoch)\n",
        "        \n",
        "        self.model.save_weights('callback_model.hdf5')\n",
        "        self.pred_model.load_weights('callback_model.hdf5')\n",
        "        \n",
        "        self.train_accuracy()\n",
        "        self.val_accuracy()\n",
        "\n",
        "        experiment.log_metric(\"train_ser\", self.train_ser)\n",
        "        experiment.log_metric(\"val_ser\", self.val_ser)\n",
        "        experiment.log_metric(\"train_ler\", self.train_ler)\n",
        "        experiment.log_metric(\"val_ler\", self.val_ler)\n",
        "\n",
        "        \n",
        "    def train_accuracy(self):\n",
        "        '''calculates accuracy on train data'''\n",
        "        train_pred = self.pred_model.predict(x_train)\n",
        "        decode_pred = K.get_value(K.ctc_decode(train_pred, input_length=np.ones(train_pred.shape[0])*train_pred.shape[1],\n",
        "                         greedy=True)[0][0])\n",
        "        \n",
        "        train_points = self.x_train.shape[0]\n",
        "        count       = 0\n",
        "\n",
        "        total_edits   = 0\n",
        "        total_lab_len = 0\n",
        "        \n",
        "        # removing all extra label or -1's induced by CTC\n",
        "        for i in range(train_points):   \n",
        "            pred_label = []  # the final label\n",
        "            \n",
        "            x = decode_pred[i]\n",
        "            for item in x:\n",
        "                if item!=-1:\n",
        "                    pred_label.append(item)\n",
        "                \n",
        "            pred_label = np.asarray(pred_label)            \n",
        "            if np.array_equal(pred_label,y_train[i]):\n",
        "                count += 1\n",
        "            \n",
        "            total_edits   += editdistance.eval(pred_label, y_train[i])\n",
        "            total_lab_len += len(y_train[i])\n",
        "        \n",
        "        self.train_acc = count/train_points*100\n",
        "        self.train_ser = 100 - self.train_acc\n",
        "        self.train_ler = total_edits/total_lab_len*100\n",
        "        \n",
        "    \n",
        "    def val_accuracy(self):\n",
        "        '''calculates accuracy on validation data'''\n",
        "        test_pred = self.pred_model.predict(x_test)\n",
        "        decode_pred = K.get_value(K.ctc_decode(test_pred, input_length=np.ones(test_pred.shape[0])*test_pred.shape[1],\n",
        "                         greedy=True)[0][0])\n",
        "        \n",
        "        test_points = self.x_test.shape[0]\n",
        "        count       = 0\n",
        "\n",
        "        total_edits   = 0\n",
        "        total_lab_len = 0\n",
        "        \n",
        "        # removing all extra label or -1's induced by CTC\n",
        "        for i in range(test_points):   \n",
        "            pred_label = []  # the final label\n",
        "            \n",
        "            x = decode_pred[i]\n",
        "            for item in x:\n",
        "                if item!=-1:\n",
        "                    pred_label.append(item)\n",
        "                \n",
        "            pred_label = np.asarray(pred_label)            \n",
        "            if np.array_equal(pred_label,y_test[i]):\n",
        "                count += 1\n",
        "\n",
        "            total_edits   += editdistance.eval(pred_label, y_test[i])\n",
        "            total_lab_len += len(y_test[i])\n",
        "        \n",
        "        self.val_acc = count/test_points*100\n",
        "        self.val_ser = 100 - self.val_acc\n",
        "        self.val_ler = total_edits/total_lab_len*100\n",
        "        \n",
        "model_save_callback = ModelCheckpoint(WRITE_DIR + \"best_model-\" + DTSTR + \".hdf5\", monitor='val_loss', verbose=1,\n",
        "    save_best_only=True, mode='auto')\n",
        "\n",
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)  # stop training if val_loss does not improve in 10 consec episodes\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RrUExzgUT2Q"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "dCGvY1QxUT2T",
        "outputId": "7de9d42a-197b-44cd-f3a2-e4fd06659631"
      },
      "source": [
        "EPOCHS      = 200\n",
        "\n",
        "model.fit(x=[x_train, y_train, train_input_length, train_label_length], y=np.zeros(training_pts), epochs=EPOCHS,\n",
        "         validation_data = ([x_test, y_test, test_input_length, test_label_length], [np.zeros(test_pts)]),\n",
        "         callbacks=[MetricCallback(model_arch, x_train, y_train, x_test, y_test, experiment), \n",
        "         model_save_callback, earlystop_callback],\n",
        "         batch_size=32, verbose=0)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "End of epoch number:  24\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.37773\n",
            "End of epoch number:  25\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.37773\n",
            "End of epoch number:  26\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.37773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-b9ee1dec728c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m          callbacks=[MetricCallback(model_arch, x_train, y_train, x_test, y_test, experiment), \n\u001b[1;32m      6\u001b[0m          model_save_callback, earlystop_callback],\n\u001b[0;32m----> 7\u001b[0;31m          batch_size=32, verbose=0)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/comet_ml/monkey_patching.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                     )\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# Call after callbacks once we have the return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/comet_ml/monkey_patching.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                     )\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# Call after callbacks once we have the return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpCG1lNVQlWz"
      },
      "source": [
        "#### Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvTfynxTQkus"
      },
      "source": [
        "predicted_output = \n",
        "\n",
        "experiment.log_confusion_matrix(desired_output, actual_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFqE48Ejd8XC",
        "outputId": "9348f853-7f2e-4bbe-a718-50a9f1806a0e"
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.ml/adityajain07/ctc-lfd/187889dffbf04c46ac573ef030c4609f\n",
            "COMET INFO:   Metrics [count] (min, max):\n",
            "COMET INFO:     batch_loss [395]          : (0.004746672697365284, 68.18843841552734)\n",
            "COMET INFO:     epoch_duration [79]       : (3.4686578050000207, 11.937504530999831)\n",
            "COMET INFO:     loss [79]                 : (0.017440063878893852, 15.215847969055176)\n",
            "COMET INFO:     train_ler [79]            : (0.046202180742931066, 85.71428571428571)\n",
            "COMET INFO:     train_ser [79]            : (0.12936610608021226, 100.0)\n",
            "COMET INFO:     val_ler [79]              : (1.5873015873015872, 85.71428571428571)\n",
            "COMET INFO:     val_loss [79]             : (0.35897934436798096, 7.7590131759643555)\n",
            "COMET INFO:     val_ser [79]              : (4.134366925064597, 100.0)\n",
            "COMET INFO:     validate_batch_loss [158] : (0.21468164026737213, 7.952761650085449)\n",
            "COMET INFO:   Others:\n",
            "COMET INFO:     trainable_params : 423687\n",
            "COMET INFO:   Parameters:\n",
            "COMET INFO:     Adam_amsgrad       : 1\n",
            "COMET INFO:     Adam_beta_1        : 0.9\n",
            "COMET INFO:     Adam_beta_2        : 0.999\n",
            "COMET INFO:     Adam_decay         : 1\n",
            "COMET INFO:     Adam_epsilon       : 1e-07\n",
            "COMET INFO:     Adam_learning_rate : 0.001\n",
            "COMET INFO:     Adam_name          : Adam\n",
            "COMET INFO:     Optimizer          : Adam\n",
            "COMET INFO:     epochs             : 200\n",
            "COMET INFO:     steps              : 49\n",
            "COMET INFO:   Uploads:\n",
            "COMET INFO:     code                : 1 (32 KB)\n",
            "COMET INFO:     environment details : 1\n",
            "COMET INFO:     filename            : 1\n",
            "COMET INFO:     installed packages  : 1\n",
            "COMET INFO:     model graph         : 1\n",
            "COMET INFO:     notebook            : 1\n",
            "COMET INFO:     os packages         : 1\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Still uploading\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb80sWEcUT2T"
      },
      "source": [
        "#### Save and Load Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMX1EcWnUT2U"
      },
      "source": [
        "model.save_weights('first_run.hdf5')\n",
        "model_arch.load_weights('first_run.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5P9cWlhpPeu"
      },
      "source": [
        "#### Accuracy on a (preferably on a held-out) batch of dataset\n",
        "In this section, simply pass a self-collected or any other dataset along with labels. Returns accuracy or the inverse of SER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfBSMHOdpMXx"
      },
      "source": [
        "def accuracy_on_batch(model, data, labels):  \n",
        "  pred        = model.predict(data)\n",
        "  decode_pred = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1],\n",
        "                         greedy=True)[0][0])        \n",
        "  points      = data.shape[0]\n",
        "  count       = 0\n",
        "                                          \n",
        "  for i in range(points):          # removing all extra -1's induced by CTC\n",
        "    pred_label = []                # the final label\n",
        "            \n",
        "    x = decode_pred[i]\n",
        "    for item in x:\n",
        "      if item!=-1:\n",
        "        pred_label.append(item)\n",
        "                \n",
        "    pred_label = np.asarray(pred_label)            \n",
        "    \n",
        "    if np.array_equal(pred_label,labels[i]):\n",
        "      count += 1            \n",
        "        \n",
        "  accuracy = count/points*100\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU4oAAT7sBDs",
        "outputId": "9e03a699-ad64-489c-8461-f4744415dcbd"
      },
      "source": [
        "weights_path = WRITE_DIR + 'best_model-2020-12-24-07-23.hdf5'\n",
        "model_arch.load_weights(weights_path)\n",
        "\n",
        "batch_accuracy = accuracy_on_batch(model_arch, x_test, y_test)\n",
        "\n",
        "print(\"The accuracy on the batch in % is: \", batch_accuracy)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy on the batch in % is:  94.375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9jheC_KUT2U"
      },
      "source": [
        "#### Inference on a single test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doBY4PybUT2U",
        "outputId": "b521bfc0-27fe-4e23-b7ea-78823460da8a"
      },
      "source": [
        "video_path     = \"/content/drive/My Drive/TCS FullTime Work/LfD/Liquid_Pouring/TADL-II/CTC-MIME/22dec/stacking4.avi\"\n",
        "\n",
        "# These params cannot be changed\n",
        "desired_shape  = (30, 800)\n",
        "n_frames       = 10\n",
        "down_f         = 8\n",
        "\n",
        "infer_object   = inference.Inference(video_path, n_frames, down_f, desired_shape, model_arch)\n",
        "image = infer_object.prep_data()\n",
        "predicted_out, final_out = infer_object.predict()\n",
        "\n",
        "print(\"Raw output: \", predicted_out)\n",
        "print(\"Final processed output: \", final_out)\n",
        "print('\\n')\n",
        "\n",
        "for primtive in final_out:\n",
        "    if primtive==0:\n",
        "        continue\n",
        "    else:\n",
        "        print(prim_map[primtive])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw output:  [ 1  4  1  5  3  0  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1]\n",
            "Final processed output:  [1 4 1 5 3 0 0]\n",
            "\n",
            "\n",
            "Reach\n",
            "Grasp\n",
            "Reach\n",
            "Release\n",
            "Retract\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHEMFlbbUT2U"
      },
      "source": [
        "### Miscellaneous (Do Not Run)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-98UU8eUT2V",
        "outputId": "368fe16c-c700-4fc2-a5bc-12f10353641c"
      },
      "source": [
        "## Saving the model\n",
        "\n",
        "model.save_weights('first_run.hdf5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f3860cb5fe1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Saving the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'first_run.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eCpPxE7UT2V",
        "outputId": "fb9d4001-83b8-434e-c814-6786ce933b7d"
      },
      "source": [
        "# model.save_weights('first_run.hdf5')\n",
        "# model_arch.load_weights('first_run.hdf5')\n",
        " \n",
        "# predict outputs on validation images\n",
        "test_points = 2\n",
        "\n",
        "# Inference data\n",
        "infer_data    = x_train[:test_points]\n",
        "infer_label   = y_train[:test_points]\n",
        "\n",
        "prediction  = model_arch.predict(infer_data)\n",
        "\n",
        "# use CTC decoder\n",
        "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
        "                         greedy=True)[0][0])\n",
        " \n",
        "\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  4  1  1  5  3  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            "  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            "  -1 -1]\n",
            " [ 1  4  1  5  3  0  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            "  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            "  -1 -1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mFzuhEQUT2W",
        "outputId": "c0f0acae-9e68-48f2-afb7-c58a6a0554cc"
      },
      "source": [
        "for i in range(test_points):\n",
        "    print(\"True label: \", infer_label[i])\n",
        "    \n",
        "    pred_lab = []\n",
        "    x = out[i]\n",
        "    for i in x:\n",
        "        if i!=-1:\n",
        "            pred_lab.append(i)\n",
        "            \n",
        "    print(\"Predicted label: \", np.asarray(pred_lab))\n",
        "    print(type(infer_label[i]))\n",
        "    print('\\n')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True label:  [1 4 1 1 5 3 0]\n",
            "Predicted label:  [1 4 1 1 5 3 0]\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "\n",
            "True label:  [1 4 1 5 3 0 0]\n",
            "Predicted label:  [1 4 1 5 3 0 0]\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABMqHME9UT2W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}